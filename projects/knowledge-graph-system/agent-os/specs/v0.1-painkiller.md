# Specification: Knowledge Graph System v0.1 - Week 1 Painkiller

## Goal

Build a minimal viable CLI tool in 2-3 days that stops the immediate pain of context loss. Manual, simple, working TODAY. Polish and automation come later.

The user is bleeding RIGHT NOW from repeating themselves across Claude sessions. We need the absolute minimum tool to stop this pain THIS WEEK.

## User Stories

- As a developer using AI tools, I want to save my Claude conversations so I don't have to repeat context across sessions
- As a developer, I want to search past conversations by keyword so I can find that thing I explained 2 days ago in seconds
- As a developer, I want to view full conversations so I can recover exact details without re-explaining
- As a developer, I want a simple CLI (not a web UI, not complexity) so I can start using it immediately

## Core Requirements

### Functional Requirements

**Must Have (Week 1):**
- Save conversations manually (copy/paste into editor)
- Search conversations by keyword (full-text search)
- View full conversation by ID
- List recent conversations
- Simple configuration (database connection)

**Must NOT Have (Week 1):**
- No web UI
- No auto-capture (Week 2+)
- No semantic search (Week 2+)
- No pgvector yet (Week 2+)
- No entity extraction yet (Week 2+)
- No graph database yet (Week 2+)

### Non-Functional Requirements

- **Installation:** Single binary, works on macOS immediately
- **Performance:** Search results in <1 second on 1000 conversations
- **Setup:** 5 minutes from `brew install postgresql` to first conversation saved
- **Usability:** CLI help text is sufficient documentation for Week 1

## Visual Design

No visual design needed - CLI only for Week 1.

## Reusable Components

### Existing Code to Leverage

**From tech stack standards:**
- PostgreSQL for database (user's preferred stack)
- Go for CLI (user's preferred language for systems/tools)
- Standard Go CLI patterns (Cobra framework)

**Patterns to follow:**
- Simple database schema with timestamps and indexes (per backend/models.md standards)
- Full-text search using PostgreSQL's built-in capabilities
- Clear error messages for users (per error-handling.md standards)
- Environment-based configuration (per conventions.md standards)

### New Components Required

**All components are new** - this is the first implementation.

**Why new:**
- No existing knowledge management tool in codebase
- No existing PostgreSQL integration to reuse
- Simple enough that reuse isn't critical for Week 1

## Technical Approach

### Database

**Technology:** PostgreSQL 16+ (via Homebrew on macOS)

**Schema:**

```sql
-- Single table: conversations
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    tags TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Full-text search index
CREATE INDEX idx_conversations_fts ON conversations
USING GIN (to_tsvector('english', content));

-- Index for title search
CREATE INDEX idx_conversations_title ON conversations
USING GIN (to_tsvector('english', title));

-- Index for recent queries
CREATE INDEX idx_conversations_created_at ON conversations (created_at DESC);
```

**Rationale:**
- Single table keeps it simple for Week 1
- GIN index on content provides fast full-text search
- PostgreSQL's `to_tsvector` provides built-in full-text search without external dependencies
- Tags stored as PostgreSQL array for future filtering (but not used Week 1)

### CLI

**Technology:** Go with Cobra framework

**Package Structure:**

```
knowledge/
├── cmd/
│   └── knowledge/
│       └── main.go           # CLI entry point
├── internal/
│   ├── cli/
│   │   ├── add.go           # 'add conversation' command
│   │   ├── search.go        # 'search' command
│   │   ├── show.go          # 'show' command
│   │   ├── list.go          # 'list' command
│   │   └── init.go          # 'init' command
│   ├── db/
│   │   ├── db.go            # PostgreSQL connection
│   │   ├── migrations.go    # Schema creation
│   │   └── queries.go       # CRUD operations
│   ├── models/
│   │   └── conversation.go  # Conversation struct
│   └── config/
│       └── config.go        # Configuration management
├── go.mod
├── go.sum
└── README.md
```

**Dependencies:**

```go
// go.mod
module github.com/yourusername/knowledge

go 1.21

require (
    github.com/spf13/cobra v1.8.0
    github.com/lib/pq v1.10.9
    github.com/spf13/viper v1.18.2
)
```

**Commands:**

1. **`knowledge init`**
   - Creates `~/.knowledge/config.yaml`
   - Prompts for database connection details
   - Creates database schema (runs migrations)
   - Output: "Knowledge graph initialized successfully"

2. **`knowledge add conversation`**
   - Opens `$EDITOR` (vim/nano/whatever user has set)
   - User pastes conversation content
   - On save/close, prompts for:
     - `Title: ` (required)
     - `Tags (comma-separated, optional): `
   - Saves to database
   - Output: "Saved conversation #42"

3. **`knowledge search <query>`**
   - Full-text search using PostgreSQL's `to_tsvector`
   - Searches both title and content
   - Returns top 10 results by relevance
   - Output format:
     ```
     #42: How to implement rate limiting (2025-10-22)
     ...we discussed using token bucket algorithm with Redis backing...

     #38: Authentication architecture decisions (2025-10-20)
     ...decided to use passkeys (WebAuthn) for primary auth...

     Found 2 results
     ```
   - Shows: ID, title, date, 200-character snippet with query term highlighted

4. **`knowledge show <id>`**
   - Fetches conversation by ID
   - Displays full conversation with metadata
   - Output format:
     ```
     Title: How to implement rate limiting
     Date: 2025-10-22 14:30:00
     Tags: go, api, redis
     ID: 42

     ────────────────────────────────────────

     [Full conversation content here]
     ```

5. **`knowledge list`**
   - Lists most recent 20 conversations
   - Sorted by created_at DESC
   - Output format:
     ```
     Recent Conversations:

     #42  How to implement rate limiting       2025-10-22
     #41  PostgreSQL indexing strategies       2025-10-22
     #40  NATS JetStream setup                 2025-10-21
     ...

     Showing 20 most recent conversations
     ```

**Configuration:**

```yaml
# ~/.knowledge/config.yaml
database:
  host: localhost
  port: 5432
  name: knowledge
  user: bertsmith          # User's macOS username
  password: ""             # Empty for local dev
  sslmode: disable         # Local development only
```

**Configuration loading:**
- Use `viper` to load config from `~/.knowledge/config.yaml`
- Support environment variable overrides: `KNOWLEDGE_DB_HOST`, `KNOWLEDGE_DB_NAME`, etc.
- Fail gracefully with clear error if config doesn't exist: "Run 'knowledge init' first"

### Data Flow

**Add Conversation Flow:**
1. User runs `knowledge add conversation`
2. CLI opens `$EDITOR` with temp file
3. User pastes conversation, saves, closes editor
4. CLI reads temp file content
5. CLI prompts for title (required)
6. CLI prompts for tags (optional)
7. CLI inserts into database
8. CLI returns conversation ID

**Search Flow:**
1. User runs `knowledge search "rate limiting"`
2. CLI builds PostgreSQL full-text query:
   ```sql
   SELECT id, title, content, created_at,
          ts_rank(to_tsvector('english', content), plainto_tsquery('english', $1)) as rank
   FROM conversations
   WHERE to_tsvector('english', title || ' ' || content) @@ plainto_tsquery('english', $1)
   ORDER BY rank DESC
   LIMIT 10;
   ```
3. CLI formats results with snippets
4. CLI displays results to user

**Show Flow:**
1. User runs `knowledge show 42`
2. CLI queries database: `SELECT * FROM conversations WHERE id = $1`
3. CLI formats and displays full conversation
4. Handle not found: "Conversation #42 not found"

**List Flow:**
1. User runs `knowledge list`
2. CLI queries: `SELECT id, title, created_at FROM conversations ORDER BY created_at DESC LIMIT 20`
3. CLI displays table format

### Error Handling

**Database Connection Errors:**
- Clear message: "Cannot connect to database. Check configuration in ~/.knowledge/config.yaml"
- Exit code: 1

**Configuration Missing:**
- Clear message: "Knowledge graph not initialized. Run 'knowledge init' first."
- Exit code: 1

**Editor Not Found:**
- Clear message: "No editor found. Set EDITOR environment variable (e.g., export EDITOR=vim)"
- Exit code: 1

**Invalid Conversation ID:**
- Clear message: "Conversation #999 not found"
- Exit code: 1

**Empty Search Results:**
- Clear message: "No conversations found matching 'your query'"
- Exit code: 0 (not an error, just no results)

### Testing Strategy

**Week 1 Testing (Minimal):**
- Manual testing of happy path for all commands
- Test on user's actual machine (macOS)
- Fix critical bugs only

**Week 2+ Testing (Proper):**
- Unit tests for database queries
- Integration tests for CLI commands
- Edge case handling
- CI/CD pipeline

## Installation & Setup

### User Journey (Week 1)

**Step 1: Install PostgreSQL**
```bash
brew install postgresql@16
brew services start postgresql@16
```

**Step 2: Create Database**
```bash
createdb knowledge
```

**Step 3: Build & Install CLI**
```bash
cd projects/knowledge-graph-system
go build -o knowledge ./cmd/knowledge
sudo mv knowledge /usr/local/bin/
```

**Step 4: Initialize**
```bash
knowledge init
# Prompts for database config
# Creates schema
```

**Step 5: Start Using**
```bash
# Save first conversation
knowledge add conversation
# ... paste conversation, add title, tags ...

# Search it later
knowledge search "authentication"

# View full conversation
knowledge show 1
```

**Total time:** 5-10 minutes from zero to first conversation saved.

## Usage Examples

### Example 1: Save a Conversation

```bash
$ knowledge add conversation
# Opens vim with empty file
# User pastes Claude conversation about rate limiting
# User saves and quits vim

Title: How to implement rate limiting in Go
Tags (optional): go, api, redis, rate-limiting

✓ Saved conversation #42
```

### Example 2: Search Conversations

```bash
$ knowledge search "rate limiting"

#42: How to implement rate limiting in Go (2025-10-23)
...we discussed using token bucket algorithm with Redis backing.
The golang.org/x/time/rate package provides an excellent implementation...

#38: API design best practices (2025-10-20)
...always include rate limiting headers (X-RateLimit-Limit,
X-RateLimit-Remaining) so clients can implement backoff...

Found 2 results
```

### Example 3: View Full Conversation

```bash
$ knowledge show 42

Title: How to implement rate limiting in Go
Date: 2025-10-23 10:30:00
Tags: go, api, redis, rate-limiting
ID: 42

────────────────────────────────────────

User: How should I implement rate limiting for my API?

Claude: There are several approaches to rate limiting in Go...

[Full conversation continues...]
```

### Example 4: List Recent Conversations

```bash
$ knowledge list

Recent Conversations:

#42  How to implement rate limiting in Go       2025-10-23
#41  PostgreSQL indexing strategies             2025-10-22
#40  NATS JetStream setup for events            2025-10-21
#39  Testing strategy for Go services           2025-10-21
#38  API design best practices                  2025-10-20

Showing 5 most recent conversations
```

## Out of Scope (Week 1)

**Not Building Now:**
- Auto-capture of Claude conversations (Week 2)
- Semantic search with embeddings (Week 2)
- pgvector integration (Week 2)
- Entity extraction (Week 2+)
- Graph relationships (Week 2+)
- Web UI (Month 2+)
- Neovim plugin (Month 3+)
- Multi-model orchestration (Month 3+)
- Tag-based filtering (Week 2)
- Edit/delete conversations (Week 2)
- Export functionality (Week 2)

**Why Deferred:**
- Week 1 = stop the bleeding (save and search)
- Week 2+ = make it better (automation, semantics)
- User needs relief NOW, polish later

## Success Criteria

**Week 1 Complete When:**

- ✅ User can save conversations (manual paste works)
- ✅ User can search conversations (keyword search returns relevant results)
- ✅ User can view full conversations (complete content displayed)
- ✅ User can list recent conversations (see what's stored)
- ✅ CLI is installed and working on user's Mac
- ✅ User uses it at least 3 times in Week 1
- ✅ User stops repeating context to Claude

**Measures of Success:**

1. **Speed:** From zero to first conversation saved in <10 minutes
2. **Usefulness:** User can find past conversations faster than scrolling conversation logs
3. **Reliability:** No crashes during normal use
4. **Simplicity:** No questions like "how do I...?" for basic operations

**What This DOESN'T Need to Be:**

- Perfect UX (manual paste is fine)
- Beautiful output (basic formatting is fine)
- Feature-complete (just save and search)
- Production-ready (local use only)

**This Needs to:**
- Work reliably for basic use case
- Be faster than current pain (manual search in files)
- Give user confidence to continue building

## Week 2 Preview (Not in Scope Now)

After Week 1 painkiller is working and being used:

**Week 2 Improvements:**
- Add auto-capture (monitor Claude Code session logs)
- Add tag-based filtering (`knowledge search --tag api`)
- Add edit/delete commands
- Add export to Markdown
- Polish error messages
- Add proper tests

**Week 3-4 (Semantic Search):**
- Add pgvector extension to PostgreSQL
- Integrate Ollama with nomic-embed-text
- Implement semantic search alongside keyword search
- Command: `knowledge find "how do we handle auth"` (meaning-based)

**But NOT NOW.**

Week 1 = minimal viable painkiller.
Week 2+ = make it better.

## Implementation Notes

### Development Approach

**Day 1:**
- Set up Go project structure
- Implement database schema and migrations
- Implement basic config loading
- Implement `knowledge init` command

**Day 2:**
- Implement `knowledge add conversation` command
- Implement `knowledge search` command
- Implement `knowledge show` command
- Test basic workflow

**Day 3:**
- Implement `knowledge list` command
- Polish error messages
- Write basic README
- Test on user's machine
- Deploy to user's PATH

**Daily Checkpoints:**
- End of each day: commit working code
- Test manually after each feature
- Deploy to user's machine for daily dogfooding

### Database Migration Strategy

**Week 1:** Simple approach
- `knowledge init` runs schema creation SQL
- No migration system needed yet
- Schema is simple enough to recreate if needed

**Week 2+:** Proper migrations
- Use golang-migrate or similar
- Version schema changes
- Support upgrades without data loss

### PostgreSQL Full-Text Search

**Using Built-in Capabilities:**

```sql
-- Create tsvector for content
to_tsvector('english', content)

-- Create query from user input
plainto_tsquery('english', 'rate limiting')

-- Match operator
to_tsvector('english', content) @@ plainto_tsquery('english', 'rate limiting')

-- Rank results by relevance
ts_rank(to_tsvector('english', content), plainto_tsquery('english', 'rate limiting'))
```

**Why This Works for Week 1:**
- No external dependencies
- Fast enough for <1000 conversations
- Good enough relevance for keyword search
- Built into PostgreSQL (no setup needed)

**When to Upgrade (Week 2+):**
- Add pgvector for semantic search
- Keep full-text search for hybrid approach
- Best of both worlds: keyword + semantic

### Editor Integration

**Opening Editor:**
```go
// Get editor from environment
editor := os.Getenv("EDITOR")
if editor == "" {
    editor = "vim" // Default fallback
}

// Create temp file
tmpfile, err := os.CreateTemp("", "knowledge-*.txt")
// ... handle error ...

// Open editor
cmd := exec.Command(editor, tmpfile.Name())
cmd.Stdin = os.Stdin
cmd.Stdout = os.Stdout
cmd.Stderr = os.Stderr
err = cmd.Run()
// ... handle error ...

// Read content
content, err := os.ReadFile(tmpfile.Name())
// ... handle error ...

// Clean up
os.Remove(tmpfile.Name())
```

**Prompting for Title/Tags:**
```go
// Use standard input
reader := bufio.NewReader(os.Stdin)

fmt.Print("Title: ")
title, _ := reader.ReadString('\n')
title = strings.TrimSpace(title)

fmt.Print("Tags (comma-separated, optional): ")
tagsInput, _ := reader.ReadString('\n')
tags := parseTags(tagsInput) // Split by comma, trim whitespace
```

### Output Formatting

**Search Results Snippet:**
```go
// Find query term in content
query := "rate limiting"
index := strings.Index(strings.ToLower(content), strings.ToLower(query))

// Extract 200 chars around query
start := max(0, index-100)
end := min(len(content), index+100)
snippet := content[start:end]

// Add ellipsis if truncated
if start > 0 {
    snippet = "..." + snippet
}
if end < len(content) {
    snippet = snippet + "..."
}
```

**Date Formatting:**
```go
// Format timestamp as YYYY-MM-DD
dateStr := timestamp.Format("2006-01-02")

// Or with time: YYYY-MM-DD HH:MM
dateTimeStr := timestamp.Format("2006-01-02 15:04")
```

## Dependencies & Prerequisites

### System Requirements

- macOS (primary target for Week 1)
- Homebrew (for PostgreSQL installation)
- Go 1.21+ (for building CLI)

### External Dependencies

```
PostgreSQL 16+         - Database
Homebrew               - Package manager for PostgreSQL
$EDITOR or vim         - For content editing
```

### Go Dependencies

```
github.com/spf13/cobra  - CLI framework
github.com/lib/pq       - PostgreSQL driver
github.com/spf13/viper  - Configuration management
```

All installed via `go mod download`.

## Alignment with Standards

**Follows user's tech stack (tech-stack.md):**
- ✅ Go for systems/tools
- ✅ PostgreSQL as primary database
- ✅ Structured logging with clear errors
- ✅ Environment-based configuration

**Follows coding style (coding-style.md):**
- ✅ Meaningful names (no abbreviations)
- ✅ Small, focused functions
- ✅ No dead code or commented blocks
- ✅ DRY principle (reusable database queries)

**Follows backend/models standards:**
- ✅ Timestamps on all tables (created_at, updated_at)
- ✅ Database constraints (NOT NULL, indexes)
- ✅ Appropriate data types (TEXT for content, VARCHAR for title)

**Follows error handling standards:**
- ✅ User-friendly error messages
- ✅ Fail fast with clear errors
- ✅ Clean up resources (temp files)

**Follows conventions (conventions.md):**
- ✅ Clear documentation (README)
- ✅ Environment variables for configuration
- ✅ Version control (git from day one)

## Final Notes

### Philosophy: Painkiller, Not Vitamin

- **Working > Perfect:** Ship something useful in 2-3 days
- **Manual > Automatic:** Copy/paste is fine for Week 1
- **Simple > Feature-rich:** Three commands (add, search, show) solve the core pain
- **Ship > Polish:** Users need relief NOW, not perfect UX

### User Context

- Part-time builder (job required, limited time)
- Needs something working ASAP
- Living the pain RIGHT NOW ("makes my skin crawl" to repeat himself)
- Will deep-dive on features later, needs relief immediately

### Path Forward

**Week 1:** This spec → minimal working tool → user relief
**Week 2:** Polish + auto-capture + better UX
**Week 3-4:** Semantic search (pgvector + Ollama)
**Month 2+:** The full infrastructure vision from roadmap

But first: stop the bleeding. Give the user a tool that works THIS WEEK.

---

**Specification complete. Ready for implementation.**

**Target delivery:** 2-3 days from start to working CLI on user's machine.

**Success measure:** User saves and searches at least 3 conversations in Week 1 without context loss.
